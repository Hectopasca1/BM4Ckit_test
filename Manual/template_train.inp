# input template for training models

# global configs
START: 0          # 0: from scratch; 1: load checkpoint from LOAD_CHK_FILE_PATH
EPOCH: 10
BATCH_SIZE: 10
VAL_BATCH_SIZE: 20 # default is the same as BATCH_SIZE
VAL_PER_STEP: 100
ACCUMULATE_STEP: 12

# I/O configs
REDIRECT: true    # whether output training logs to OUTPUT_PATH or directly print on screen.
SAVE_CHK: true
LOAD_CHK_FILE_PATH: your/path/to/checkpoint.pt
CHK_SAVE_PATH: your/path/to/checkpoint/
CHK_SAVE_POSTFIX: your_checkpoint_postfix
OUTPUT_PATH: your/path/to/output/log/
OUTPUT_POSTFIX: your_log_postfix

# loss configs
LOSS: Energy_Loss  # 'MSE': nn.MSELoss, 'MAE': nn.L1Loss, 'Hubber': nn.HuberLoss, 'CrossEntropy': nn.CrossEntropyLoss 'Energy_Force_Loss': Energy_Force_Loss, 'Energy_Loss': Energy_Loss
LOSS_CONFIG:
  loss_E: SmoothMAE
#  loss_F: MSE
#  coeff_E: 1.
#  coeff_F: 0.01
METRICS:  # tuple of E_MAE, F_MAE, F_MaxE, E_R2, MSE, MAE, R2, RMSE
  - E_MAE
  - E_R2
#  - F_MaxE

# model configs
MODEL_NAME: GemNet_OC  # See arXiv:2204.02782, hyperparameters was obtained from ACS Catal. 2023, 13, 5, 3066â€“3084.
MODEL_CONFIG: {}
  # model hyperparameters ...
  # ...

# optimizer configs
OPTIM: AdamW
OPTIM_CONFIG:
  lr: 2.e-4
  # ...
